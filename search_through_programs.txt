How does search through programs work?
 Is the space continuous or not?
 
A reasonable metric might be edit distance

This allows measurement of distance between strings of different length

But I could always just call empty space 0
 But that may skew the results
 
Is there a topology induced by edit distance?


Question 1:
 Relationship between lisp and lambda calculus

First gather info abt lambda calc

Consists of constructing lambda terms and performing reduction opertations on them
 In simplest form of lambda calc, terms only build using 
  1. Variable        x
  2. Abstraction     (\x.M) <-- like (fn [x] (* 2 x))
  3. Application     (M N)  <-- like ((fn [x] (* 2 x)) 3)

Producing expressions such as (λx.λy.(λz.(λx.z x) (λy.z y)) (x y)). 

Reduction operations are
 alpha-conversion -- renaming bound (formal) variables in the expression -- to avoid name collisions
  (λx.M[x]) → (λy.M[y])
 beta-conversion  -- substituting boudn variable by the argument expression
  ((λx.M) E) → (M[x:=E])

can be typed or untyped

Motivation is to provide a simple semantics to study computable functions
The semantics are made simple by two simplifications
 1. Treating fxns as "anonymous"
 2. Treating all fxns as single input -- through currying

A valid lambda calc expression is called a "lambda term"
 (some strings of lambda characters are not valid programs)

How to build all syntactically valid lambda terms:
 1. a variable, x, is itself a valid lambda term
 2. if t is a lambda term and x is a variable, then (\x.t) is a lambda term (abstraction)
 3.  if t and s are lambda terms then (ts) is a lambda term (application)

Nothing else is a lambda term
 (usually in practice outer parens not written) 
(x) does not work in scheme or clojure
But for anything else, should write out full

This inductive definition provides way to loop through programs 
At each step, choose abstraction or join lambda terms 
 But could just put x in lambda 
 Can do for each term 

A single lambda expression looks like a tree
(f x x) really means ((f x) x) due to currying

Look at abstract symbol tree to see what this tree looks like

Free variables -- also defined inductively 
 The free variables of x are just x
 The set of free vars of \x.t is the set of free vars of t, w/o x
 The set of free vars of ts is the union of the free vars of t and s

Where am I with respect to writing a program that searches through space of programs

 Might as well write most naive version then less naive ones

First just do random characters
Should do this in scheme so I have a more uniform syntax

Learned some to be able to do this
 Do random characters
 
Do this with macros
 Read about macros
 Read https://en.wikibooks.org/wiki/Scheme_Programming/Macros
  and do examples

Then write this thing

Also be thinking about how one could have a language st small changes in program result in small changes in the output of the program

 
https://en.wikibooks.org/wiki/Scheme_Programming/Macros 
Wait, I need to look @ a guile specific macro page

https://www.gnu.org/software/guile/manual/html_node/Macros.html

A macro is a binding between a keyword and a syntax transformer
Guile 
 define-syntax keyword transformer 
 let-syntax ((keyword transformer) ...) exp1 exp2 ...
 letrec-syntax ((keyword transformer) ...) exp1 exp2 ...

define-sytntax

(define-syntax when
  (syntax-rules ()
    ((when condition exp ...)
     (if condition
         (begin exp ...)))))

(when #t
  (display "hey ho\n") 
  (display "let's go\n"))
-| hey ho
-| let's go
 
_when_ binding is bound w/ define-syntax

define-syntax keyword transformer
 Bind keyword to the syntax transformer obtained by evaluation transformer
 After a macro has been defined, further instances of keyword in Scheme source code will invode the syntax transformer defined by transformer

let-syntax 
 Bind each keyword to its corresponding transformer while expanding exp1 exp2 ...
 A let-syntax binding only exists @ expansion time
  As in it's not like define -- more like let

letrec-syntax
 I think that letrec is to let as letrec-syntax is to let-syntax
So would be useful to understand letrec

Looking at local variable binding

As opposed to defs @ the top level which creates bidning that are visible to all code in a module, it is also possible to define vars which are only visible in a well-defined part of the program
Normally this part of a program will be a procedure or a subexpression of a procedure

W/ constructs for local binding (let, let*, letrec, and letrec*), the Scheme lang has a block structure like most other porgramming langs since the days of ALGOL

Most basic local binding construct is let

syntax: let bindings body
bindings has form
 ((variable1 init1) ...)

syntax: let* bindings body
 similar to let, but the variables bindings are performed sequentially, so all init expressions are allowed to use the vars defined on their left in the binding list

syntax: letrec bindings body
 Now can access vars in any of the other inits, even if they haven't been defined yet
 Can't actually be called until defined though -- because co-recursive

letrec* adds in the sequential notion again, so the definition from the first can actually be evaluated in the second


So back to letrec-syntax -- expansion produced by transformer may reference a keyword bound by the same letrec-syntax 

In all of the above (define-syntax, let-syntax, and letrec-syntax)
 There is a procedure syntax-rules (), that is in the transformer

syntax-rule macros are simple, pattern-driven syntax transformers
Syntax: syntax-rules literals (pattern template) ...
 Create a syntax transformer that will rewrite an expression using the rules embodied in the pattern and template clauses

What are the elipses?

A subpattern followed by `...' can match zero or more elements of the input. It is an error for `...' to appear in literals. Within a pattern the identifier `...' must follow the last element of a nonempty sequence of subpatterns. 
 
_____________
Aside: what is rigor?

I think that a constructive proof is more rigorous than a first order proof
Rigorous means air-tight
 That given the argument, the result must follow from the premises more necessarily
Finitary is even more rigorous
So maybe there is actually a trade-off between rigor level and how much you can say 
 Or even what you can talk about 
Having an undecidable program (like physics equations) may be a good heuristic in trying to make more decideable approximations (physics engines)
______________

Goal is to search through space of well formed lisp programs
 The two operations I have to move through the space is abstraction and merge
 abstraction: term -> term w/ up to one more free variable
 application: merge takes in two terms and outputs one term
  So building up graph(node = term, 2 types of edges -- abstraction and application)
 abstraction can create a single edge
 and application can create edges to a new node

So the algorithm would start with x
Then get do abstraction, for each free variables in the term
So we have 

(x) --> (\x.(x)) (identity)
Then merge (but what side? -- both)

                (x)
((x)(\x.(x))) <- | -> ((\x.x)(x))
              (\x.x)

But what to do about solitary x -- should represent a variable that is not yet defined
\x.x + y is syntactically valid
 It is in scheme as well. 
What is the minimum valid lambda term?
 Have to define x, I think
 Could I define it to be an actual value, and try several seeds

Getting bogged down -- learn how to use the syntax-rules macros
Actually I don't think that I need a macro for what I am trying to do 
 Just a loop should work
 And its good that scheme implements proper tail recursion because that'll be important

(while condition body ...)

(while (< x 5) (set! x (+ 1 x)))

Explored alternate models of computations
Lambda calc --> SKI + Unlambda --> B,K --> Iota, Jot, Zot -- based on single operator

Using Zot because can take input
 So can create functions
 Alternately, may want to not take input, and just look at what is outputted
 But I think need Zot for output

Can do a bash program where I enter in the bit sequence and get the output -- via zot program
What I want to do now is just accept the string from within the scheme program itself

This way I can do the internal loops without messing with the interface between bash and scheme

But unsure if I can do this as a single string or if I have to do it with the string by string
My current attempt is not making any output

Not sure that all programs even create output
Maybe that is the current issue

Maybe can read directly from the file
Know that I can read whole thing from port with (read (open-input-file "rev2.zot"))

Pretty sure that the data is read one character at a time that creates the a form like
 (define q ((((lambda (c) (c I)) one) zero) one))
 ((q output) print)

output is shorthand for (K (K (K (K (K (K I))))))
In other words

((((output I) one) zero) one)

Where zero and one are shorthand for
(define zero (lambda (c) (c (lambda (f) ((f S) K)))))
(define one (lambda (c) (lambda (L)
              (L (lambda (l) (lambda (R)
                       (R (lambda (r) (c (l r))))))))))

So this whole thing gets read into a big scheme expression, and fed to print
which takes in two arguments
 Unsure if we can put in an arbitrary string and get an output
 I would think so

Trying to set up port as rev.zot
 But not getting any output
This is taking too long
Let's try to take shortest path -- take existing functionality and input from bash

was able to do with bash, but it would appear that most programs make no output, and the programs that do have output are functions -- not output strings

for ((i=1; i<=10000; i++)); 
    do OUTPUT=$(echo "obase=2;$i" | bc | guile -s zot.scm); 
        if [ -n $OUTPUT ]; then echo $i $OUTPUT >> output.txt; fi; done

571 of the 10000 are functions
The produce no output
Most are producing a bunch of while space -- a BUNCH of white space
 alternating increasing 1,2,1,3,1,4 ...
Made safer by replacing all $VAR w/ "${VAR}", and got rid of white space thing

for ((i=1; i<=30; i++)); do 
    OUTPUT="$(echo "obase=2;${i}" | bc | guile -s zot.scm)"; 
    SIZE="$(echo -n "${OUTPUT}" | wc -c)"; 
    if [ $SIZE -gt 0 ]; 
        then echo "${i}" "${OUTPUT}" >> export.txt; 
    fi; 
done

Wrote to search_picky.sh
Look for bash alternatives to do this kind of stuff, because that was a huge pain to write
 Note to look into Pyed Piper and Plumbum later
Also, destroyed the first 20000 results, so good to add those back in

Want to do some analysis on the output
    cat export.txt | grep '^[0-9 ]*$'
^^gets lines that output text^^

for ((i=1; i<=100000; i++)); do
    OUTPUT="$(echo "obase=2;${i}" | bc | guile -s zot.scm)";
    echo "${OUTPUT}" >> export.txt;
done

Would make sense to visualize as a tree
Also formatting would be better without number
 Since I am doing post-processing, it was a mistake to get rid of the empty spaces
 Fixed -- nice output 

Now can do post processing with python -- jupyter notebook
What I want to do is visualize this as a tree
Because the relationship between nth and (n+1)th program is less interesting than nth to (2*n)th program
 Maybe it is the case that once a program output are numbers like 0010, then mult by two will preserve that property

Could also find this out by understanding iota better

Running up to first 100000 programs

Able to read in text in jupyter notebook
 First let's read all non-empty lines
 Got it -- how to visualize?
  Could just go high on plot when non-empty -- good enough
  Looks like they occur in groups
  Fairly linearly spaced
 Create viz of integral to check linearity 
 Pretty linear -- Looks like a slope of 1 nonempty per 10
 put on slider to check the length -- extended length
  very linear! -- slope converges on ~ 1/20

Now inspect the number of programs that produce numeric answers
Wasn't getting right grep results, because was not using echo -n in my print output  
 recreate -- add as background process
 Get rid of -n again -- puts everything onto one line lol
Re-run

Maybe the issue before had to do with whitespace characters
Look at vim show spaces -- :set list
There are dollar signs ... this is the issue -- more precisely '\n' characters
 Fixed

Now getting a good look at the binary outputs
They definitely cluster, but that may be just because the non-empties cluster
 They cluster much more than the non-empties
 Almost like there are families of the binary outputs
As for the density, it is about 1 or 2 binary outputs out of 1000 samples

Now would like to explore the tree structure of this dataset
 Could list out programs using a binary tree
 Branch left = 2*n, Branch right = 2*n + 1
 This is really big, potentially hard to draw insight from

Let's just learn a decision tree classifier on the numerical outputs and see if anything interesting pops out
Did not produce a clear separation in the slightest
 Makes sense though
At list this showed me how to visualize digraphs -- use this to make tree of programs

Explored space, did not find any obvious patterns on a cursory search
I have computed the results of the first 500,000 programs
 But I don't think that this is nearly high enough to get any interesting programs
 All of my binary outputs have been 0 or 1 
The play may not be to search exhaustively, but rather to find certain trends/large scale patterns that let us search the space more effectively.
